{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 1: Employee Performance Bonus Eligibility"
      ],
      "metadata": {
        "id": "DiUIuzFgQaUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-UmCQI-He9",
        "outputId": "63ab9e59-da9f-4633-9a44-98b9696b67a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Performers Eligible for Bonus: Ravi, Kiran (Score: 92)\n"
          ]
        }
      ],
      "source": [
        "employees = {\n",
        "    \"Ravi\": 92,\n",
        "    \"Anita\": 88,\n",
        "    \"Kiran\": 92,\n",
        "    \"Suresh\": 85\n",
        "}\n",
        "# Determine the highest score present in the group\n",
        "# This acts as our Threshold for eligibility\n",
        "max_score=max(employees.values())\n",
        "top_p=[]\n",
        "# Iterate through the dictionary to find all matches for the max score\n",
        "for n, s in employees.items():\n",
        "    if s==max_score:\n",
        "        top_p.append(n)\n",
        "print(\"Top Performers Eligible for Bonus:\", \", \".join(top_p), f\"(Score: {max_score})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 2: Search Query Keyword Analysis"
      ],
      "metadata": {
        "id": "7I2dCz5PRREi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "user =\"Buy mobile phone buy phone online\"\n",
        "# Convert to lowercase to ensure \"Buy\" and \"buy\" are treated as the same word\n",
        "user = user.lower()\n",
        "# Remove any punctuation marks that might be attached to words\n",
        "for p in string.punctuation:\n",
        "    user= user.replace(p, \"\")\n",
        "# Break the sentence into a list of individual words\n",
        "words= user.split()\n",
        "# a frequency map (dictionary) of every word found\n",
        "freq = {}\n",
        "for word in words:\n",
        "    if word in freq:\n",
        "        freq[word]+=1\n",
        "    else:\n",
        "      freq[word]=1\n",
        "result={}\n",
        "# Extract only the keywords that appear more than once (duplicates/spikes)\n",
        "for word, count in freq.items():\n",
        "    if count>1:\n",
        "        result[word]=count\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afuoWNKWRSh7",
        "outputId": "ab363c95-118a-4e25-968c-8db136242f5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'buy': 2, 'phone': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 3: Sensor Data Validation"
      ],
      "metadata": {
        "id": "uvXCtS4IUO8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "readings=[3,4,7,8,10,12,5]\n",
        "correct_read=[]\n",
        "for hour,reading in enumerate(readings):\n",
        "  if reading%2==0:\n",
        "    correct_read.append((hour,reading))\n",
        "\n",
        "print(\"Valid Sensor Readings (Hour, Value):\")\n",
        "print(correct_read)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUSkwyT2USMz",
        "outputId": "8101088b-4ace-43f3-a4b7-2996d1a0db55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Sensor Readings (Hour, Value):\n",
            "[(1, 4), (3, 8), (4, 10), (5, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 4: Email Domain Usage Analysis"
      ],
      "metadata": {
        "id": "usNySb6zVdIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emails = [\n",
        "    \"ravi@gmail.com\",\n",
        "    \"anita@yahoo.com\",\n",
        "    \"kiran@gmail.com\",\n",
        "    \"suresh@gmail.com\",\n",
        "    \"meena@yahoo.com\"\n",
        "]\n",
        "domain_counts={}\n",
        "total_emails=len(emails)\n",
        "\n",
        "for email in emails:\n",
        "    # Split at '@' and take the part after it\n",
        "    domain=email.split('@')[1]\n",
        "    domain_counts[domain]=domain_counts.get(domain, 0) + 1\n",
        "\n",
        "# Calculate and display percentages\n",
        "for domain, count in domain_counts.items():\n",
        "    percentage=(count/total_emails)*100\n",
        "    print(f\"{domain}: {percentage:.0f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJfcyLbWVgGY",
        "outputId": "ecbd3ed8-33bb-426c-c047-44142b558e75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gmail.com: 60%\n",
            "yahoo.com: 40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 5: Sales Spike Detection"
      ],
      "metadata": {
        "id": "Sf2pCn6_WHxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales=[1200, 1500, 900, 2200, 1400, 3000]\n",
        "avg_sales=sum(sales)/len(sales)\n",
        "threshold=avg_sales*1.30\n",
        "print(f\"Average Sales: {avg_sales:.2f}\")\n",
        "print(f\"Spike Threshold: {threshold:.2f}\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# Detect and display spikes\n",
        "for index,value in enumerate(sales):\n",
        "    if value>threshold:\n",
        "        # Day number is index + 1\n",
        "        print(f\"Day {index + 1}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8IOh8sqWTVi",
        "outputId": "65a8c27d-a9fa-4f66-e0c5-2c1d1afa8295"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sales: 1700.00\n",
            "Spike Threshold: 2210.00\n",
            "-------------------------\n",
            "Day 6: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement 6: Duplicate User ID Detection"
      ],
      "metadata": {
        "id": "jifQhw2GWxoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids=[\"user1\", \"user2\", \"user1\", \"user3\", \"user1\", \"user3\"]\n",
        "# Count the frequency of each user ID\n",
        "id_counts={}\n",
        "for uid in user_ids:\n",
        "    id_counts[uid]=id_counts.get(uid, 0)+1\n",
        "# Identify and display only the duplicates\n",
        "for uid,count in id_counts.items():\n",
        "    if count>1:\n",
        "        print(f\"{uid} → {count} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqUZY1rXW1Vn",
        "outputId": "e6084cd8-90db-4a70-e00b-4933d5931149"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate User ID Detection:\n",
            "user1 → 3 times\n",
            "user3 → 2 times\n"
          ]
        }
      ]
    }
  ]
}